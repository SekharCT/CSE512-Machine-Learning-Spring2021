{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d7c58f8e26b94a3abe957b757221777e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c7e63dfa79ed4b219e5030035f75c3eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cf478476299148e8b502364655453e79",
              "IPY_MODEL_b3b97046d73d4d05944b8413de102bd4"
            ]
          }
        },
        "c7e63dfa79ed4b219e5030035f75c3eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf478476299148e8b502364655453e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d5d5bfbcb4da451f850966ee097731e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6316801b5dd44d18e6943c24f134509"
          }
        },
        "b3b97046d73d4d05944b8413de102bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_075ed9c91b104a54b6fe66f696e69903",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:04&lt;00:00, 34407737.23it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a35f7d47c40474a8e5f5f4669a8e6f2"
          }
        },
        "d5d5bfbcb4da451f850966ee097731e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6316801b5dd44d18e6943c24f134509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "075ed9c91b104a54b6fe66f696e69903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a35f7d47c40474a8e5f5f4669a8e6f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c0fb6eea8ce402ca7e248d0b151cea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c87ea4e4835c4607ad8013bdb2e03ac4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ef6d2567affb4b7ea7eebd27bea14c6f",
              "IPY_MODEL_a785f22161bc4f9e86553cab270ff6b9"
            ]
          }
        },
        "c87ea4e4835c4607ad8013bdb2e03ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef6d2567affb4b7ea7eebd27bea14c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_00b001b2534d4da78c177774753b3639",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7ac672ce2ef4094af0f9a72217c38be"
          }
        },
        "a785f22161bc4f9e86553cab270ff6b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ee81c32b7604b8ca6c819a04185b725",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 92.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73b74af694b34de58e35d7f942705d11"
          }
        },
        "00b001b2534d4da78c177774753b3639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7ac672ce2ef4094af0f9a72217c38be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ee81c32b7604b8ca6c819a04185b725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73b74af694b34de58e35d7f942705d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx6kVpLaSbey"
      },
      "source": [
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFs9rGUMSsCD",
        "outputId": "79071a47-d187-45e2-dd9d-b2af6eac43af"
      },
      "source": [
        "shape = (3,2)\n",
        "x = torch.rand(shape, dtype=float)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3868, 0.7403],\n",
            "        [0.6417, 0.5854],\n",
            "        [0.1191, 0.1833]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-TOQAHyS-g-",
        "outputId": "cd701662-c383-403b-eb0d-bf52b19d44be"
      },
      "source": [
        "y = torch.ones_like(x)\n",
        "print(y, y.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], dtype=torch.float64) torch.Size([3, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8Hnct_oTIqs",
        "outputId": "a4316f6b-cff6-49e2-e194-7c994144d94d"
      },
      "source": [
        "out = x + y\n",
        "print(out)\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.3868, 1.7403],\n",
            "        [1.6417, 1.5854],\n",
            "        [1.1191, 1.1833]], dtype=torch.float64)\n",
            "tensor([[1.3868, 1.7403],\n",
            "        [1.6417, 1.5854],\n",
            "        [1.1191, 1.1833]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HALFqkBIUuQb",
        "outputId": "afdb0c6f-cb39-4620-c658-7293c0c4b698"
      },
      "source": [
        "x = np.random.rand(3,2)\n",
        "print(x)\n",
        "\n",
        "tensor_x = torch.from_numpy(x)\n",
        "print(tensor_x)\n",
        "\n",
        "numpy_x = tensor_x.numpy()\n",
        "print(numpy_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.35990055 0.82630721]\n",
            " [0.25775084 0.98181074]\n",
            " [0.46863991 0.85011467]]\n",
            "tensor([[0.3599, 0.8263],\n",
            "        [0.2578, 0.9818],\n",
            "        [0.4686, 0.8501]], dtype=torch.float64)\n",
            "[[0.35990055 0.82630721]\n",
            " [0.25775084 0.98181074]\n",
            " [0.46863991 0.85011467]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RzWgMEOVUZR",
        "outputId": "e21f17db-3a32-4717-c7a4-c5088688abd3"
      },
      "source": [
        "x = torch.rand(3,2, requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "y = x*10 + 0.1\n",
        "print(y)\n",
        "\n",
        "out = torch.max(y)\n",
        "print(out)\n",
        "\n",
        "out.backward()\n",
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9448, 0.1139],\n",
            "        [0.1096, 0.7247],\n",
            "        [0.6129, 0.0045]], requires_grad=True)\n",
            "tensor([[9.5477, 1.2387],\n",
            "        [1.1963, 7.3470],\n",
            "        [6.2293, 0.1450]], grad_fn=<AddBackward0>)\n",
            "tensor(9.5477, grad_fn=<MaxBackward1>)\n",
            "tensor([[10.,  0.],\n",
            "        [ 0.,  0.],\n",
            "        [ 0.,  0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sfuWn79ZVug",
        "outputId": "0ab1957e-b632-4b66-fe01-45c8965916e6"
      },
      "source": [
        "#--------------------------------------------------\n",
        "#       Define Network Architecture\n",
        "#--------------------------------------------------\n",
        "class TNet(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(TNet,self).__init__()  \n",
        "\n",
        "      self.conv1 = nn.Conv2d(3, 64, 3) \n",
        "      self.layer1 = torch.nn.Sequential(\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(4, stride=4), \n",
        "      )\n",
        "      self.conv2 = nn.Conv2d(64, 128, 3)\n",
        "      self.layer2 = torch.nn.Sequential(\n",
        "\n",
        "        nn.Sigmoid(),\n",
        "        nn.MaxPool2d(2, stride=2), \n",
        "      )\n",
        "      \n",
        "      self.classifier = nn.Sequential(\n",
        "         nn.Linear(512, 16), \n",
        "      )\n",
        "      self.dropout = nn.Dropout(0.5)\n",
        "      \n",
        "    def forward(self, x):\n",
        "      x = self.conv1(x)\n",
        "      x = self.layer1(x)\n",
        "      x = self.conv2(x)\n",
        "      x = self.layer2(x)  \n",
        "      x = torch.flatten(x, 1)\n",
        "      x = self.dropout(x)\n",
        "      x = self.classifier(x)\n",
        "      return x  \n",
        "\n",
        "model = TNet()\n",
        "#model = model.cuda()\n",
        "\n",
        "print (len(list(model.parameters())))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bG_FMwmZ-Bw",
        "outputId": "f3451210-301b-49b9-f54a-22425aec2fe5"
      },
      "source": [
        "input = torch.randn(1, 3, 32, 32)\n",
        "out = model(input)\n",
        "\n",
        "print(out)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.2607, -0.7261,  0.5427,  0.1701, -0.4174, -0.3128, -0.6538, -0.7719,\n",
            "          0.7229, -0.1859,  0.6547,  0.1600,  0.0373, -0.2867, -0.0388,  0.2156]],\n",
            "       grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbS_-RHkbogG",
        "outputId": "f405db5c-3dd5-415e-b892-a3808e38be90"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "target = torch.randn(16)  \n",
        "target = target.view(1, -1)  \n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "out = model(input)\n",
        "\n",
        "loss = criterion(out, target)\n",
        "print(loss)\n",
        "\n",
        "\n",
        "\n",
        "model.zero_grad()\n",
        "print('conv1.bias.grad before backward')\n",
        "\n",
        "print(model.conv1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "optimizer.step()\n",
        "\n",
        "print('layer 2.bias.grad after backward')\n",
        "print(model.conv2.bias.grad)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.2815, grad_fn=<MseLossBackward>)\n",
            "conv1.bias.grad before backward\n",
            "None\n",
            "layer 2.bias.grad after backward\n",
            "tensor([ 0.0034, -0.0040,  0.0000, -0.0003,  0.0239,  0.0015,  0.0097, -0.0021,\n",
            "        -0.0091, -0.0139,  0.0000,  0.0015,  0.0097, -0.0138,  0.0047, -0.0092,\n",
            "         0.0083,  0.0153, -0.0112,  0.0035,  0.0187, -0.0122,  0.0075,  0.0153,\n",
            "        -0.0075, -0.0056,  0.0035, -0.0042,  0.0155,  0.0105,  0.0103,  0.0105,\n",
            "        -0.0029,  0.0069,  0.0160,  0.0007,  0.0102,  0.0021,  0.0276,  0.0025,\n",
            "         0.0120, -0.0113,  0.0084, -0.0005,  0.0066,  0.0048, -0.0066,  0.0006,\n",
            "         0.0269,  0.0125, -0.0098, -0.0013,  0.0081, -0.0045,  0.0148, -0.0059,\n",
            "        -0.0044,  0.0091,  0.0102, -0.0115,  0.0015,  0.0072, -0.0018, -0.0144,\n",
            "         0.0139,  0.0137, -0.0066, -0.0090,  0.0050,  0.0160, -0.0044,  0.0024,\n",
            "        -0.0010,  0.0025,  0.0039,  0.0011, -0.0085, -0.0055,  0.0101,  0.0090,\n",
            "        -0.0054,  0.0112,  0.0011,  0.0071,  0.0143, -0.0016,  0.0084, -0.0090,\n",
            "         0.0053, -0.0094,  0.0087, -0.0151,  0.0000,  0.0042, -0.0063, -0.0105,\n",
            "        -0.0076, -0.0101,  0.0175,  0.0114,  0.0024,  0.0041,  0.0099,  0.0121,\n",
            "         0.0078,  0.0035,  0.0026,  0.0030,  0.0076,  0.0104,  0.0026,  0.0026,\n",
            "        -0.0119,  0.0053, -0.0011, -0.0005, -0.0002,  0.0099,  0.0084,  0.0017,\n",
            "         0.0126,  0.0174,  0.0184,  0.0099,  0.0155,  0.0167, -0.0059,  0.0059])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119,
          "referenced_widgets": [
            "d7c58f8e26b94a3abe957b757221777e",
            "c7e63dfa79ed4b219e5030035f75c3eb",
            "cf478476299148e8b502364655453e79",
            "b3b97046d73d4d05944b8413de102bd4",
            "d5d5bfbcb4da451f850966ee097731e6",
            "b6316801b5dd44d18e6943c24f134509",
            "075ed9c91b104a54b6fe66f696e69903",
            "0a35f7d47c40474a8e5f5f4669a8e6f2"
          ]
        },
        "id": "vVXeAgh2eKv0",
        "outputId": "e3443c44-47ba-494d-b8bd-01549af37e9f"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7c58f8e26b94a3abe957b757221777e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs-CtswHgP47"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tQryayZgdDd",
        "outputId": "80e22860-3194-407c-d5aa-447e2924152f"
      },
      "source": [
        "\n",
        "\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.307\n",
            "[1,  4000] loss: 2.037\n",
            "[1,  6000] loss: 1.898\n",
            "[1,  8000] loss: 1.796\n",
            "[1, 10000] loss: 1.740\n",
            "[1, 12000] loss: 1.699\n",
            "[2,  2000] loss: 1.647\n",
            "[2,  4000] loss: 1.621\n",
            "[2,  6000] loss: 1.583\n",
            "[2,  8000] loss: 1.565\n",
            "[2, 10000] loss: 1.562\n",
            "[2, 12000] loss: 1.513\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti43aLLqizyh",
        "outputId": "11e1f7c2-947d-42e7-ba74-34775537520f"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 45 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGQytPE5i1HB",
        "outputId": "96f2b201-37fd-4063-adbf-2e600f0635e2"
      },
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
        "                                                   accuracy))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for class plane is: 50.1 %\n",
            "Accuracy for class car   is: 52.0 %\n",
            "Accuracy for class bird  is: 46.3 %\n",
            "Accuracy for class cat   is: 25.4 %\n",
            "Accuracy for class deer  is: 28.6 %\n",
            "Accuracy for class dog   is: 42.2 %\n",
            "Accuracy for class frog  is: 58.9 %\n",
            "Accuracy for class horse is: 40.6 %\n",
            "Accuracy for class ship  is: 46.5 %\n",
            "Accuracy for class truck is: 63.9 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdFCA6nEdk2i"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiRhq1INdq9h"
      },
      "source": [
        "#--------------------------------------------------\n",
        "#       Model Training Function\n",
        "#--------------------------------------------------\n",
        "import torch.optim as optim\n",
        "import time\n",
        "  \n",
        "def trainModel(net, trainloader, train_option, testloader=None):  \n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  lr = train_option['lr']\n",
        "  epoch = train_option['epoch']\n",
        "  device = train_option['device'] if 'device' in train_option.keys() else 'cpu'\n",
        "  log_iter = train_option['log_iter'] if 'log_iter' in train_option.keys() else 1000\n",
        "  eval_epoch = 1\n",
        "  \n",
        "  if 'optimizer' in train_option.keys():\n",
        "    optimizer = train_option['optimizer']\n",
        "  else:\n",
        "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "  start_time = time.time()\n",
        "  if device == 'gpu':\n",
        "    net = net.cuda()\n",
        "    \n",
        "  iters = 0\n",
        "  running_loss = 0.0\n",
        "  for ep in range(epoch):\n",
        "    net.train()        \n",
        "    for iter, (x, y) in enumerate(trainloader):\n",
        "      iters += 1\n",
        "      batch_x = Variable(x).float()\n",
        "      batch_y = Variable(y).long()\n",
        "      if device == 'gpu':\n",
        "        batch_x = batch_x.cuda()\n",
        "        batch_y = batch_y.cuda()\n",
        "\n",
        "      outputs = net(batch_x)\n",
        "      loss = loss_func(outputs, batch_y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "      \n",
        "      time_lapse = time.strftime('%H:%M:%S', time.gmtime(time.time() - start_time))\n",
        "      if iter % log_iter == 0:\n",
        "        print('Epoch:{:2d} | Iter:{:5d} | Time: {} | Train Loss: {:.4f} | Average Loss: {:.4f} '.format(ep+1, iter, time_lapse, loss.item(), running_loss/iters))\n",
        "   \n",
        "    if testloader is not None and ep % eval_epoch == 0:\n",
        "      evalModel(net, testloader)\n",
        "  \n",
        "  return net"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqX5n-kieij2"
      },
      "source": [
        "#--------------------------------------------------\n",
        "#       Model Evaluating Function\n",
        "#--------------------------------------------------\n",
        "import time\n",
        "  \n",
        "def evalModel(net, testloader): \n",
        "  acc = 0.0\n",
        "  count = 0\n",
        "  start_time = time.time()\n",
        "  device = 'gpu' if next(net.parameters()).is_cuda else 'cpu'\n",
        "  net.eval()\n",
        "  \n",
        "  for iter, (x, y) in enumerate(testloader):\n",
        "        count += x.shape[0]\n",
        "        batch_x = Variable(x).float()\n",
        "        batch_y = Variable(y).long()\n",
        "        if device == 'gpu':\n",
        "          batch_x = batch_x.cuda()\n",
        "          batch_y = batch_y.cuda()\n",
        "        outputs = net(batch_x)\n",
        "        acc += torch.sum(outputs.max(1)[1]==batch_y)\n",
        "        \n",
        "  time_lapse = time.strftime('%H:%M:%S', time.gmtime(time.time() - start_time))        \n",
        "  print('Accuracy: {:5f} | Time: {}'.format(acc/count,time_lapse))\n",
        "  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "1c0fb6eea8ce402ca7e248d0b151cea3",
            "c87ea4e4835c4607ad8013bdb2e03ac4",
            "ef6d2567affb4b7ea7eebd27bea14c6f",
            "a785f22161bc4f9e86553cab270ff6b9",
            "00b001b2534d4da78c177774753b3639",
            "b7ac672ce2ef4094af0f9a72217c38be",
            "2ee81c32b7604b8ca6c819a04185b725",
            "73b74af694b34de58e35d7f942705d11"
          ]
        },
        "id": "g3NKSwy3ep9c",
        "outputId": "1c8be533-3d2c-4912-8d81-d535242ad541"
      },
      "source": [
        "import torchvision.models as models\n",
        "resnet =  models.resnet18(pretrained=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c0fb6eea8ce402ca7e248d0b151cea3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCo2LN0nfRE0"
      },
      "source": [
        "resnet.fc = nn.Linear(512,10)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhlXyzLWe3US",
        "outputId": "5621672a-182b-49ea-b32d-364b8e91f423"
      },
      "source": [
        "net = resnet\n",
        "train_option = {}\n",
        "train_option['lr'] = 0.002\n",
        "train_option['epoch'] = 2\n",
        "train_option['device'] = 'gpu'\n",
        "train_option['optimizer'] = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "model = trainModel(net, trainloader, train_option, testloader)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Iter:    0 | Time: 00:00:00 | Train Loss: 2.6897 | Average Loss: 2.6897 \n",
            "Epoch: 1 | Iter: 1000 | Time: 00:00:13 | Train Loss: 2.2425 | Average Loss: 1.9986 \n",
            "Epoch: 1 | Iter: 2000 | Time: 00:00:26 | Train Loss: 1.8283 | Average Loss: 1.9849 \n",
            "Epoch: 1 | Iter: 3000 | Time: 00:00:40 | Train Loss: 2.1314 | Average Loss: 1.9832 \n",
            "Epoch: 1 | Iter: 4000 | Time: 00:00:53 | Train Loss: 1.9232 | Average Loss: 1.9730 \n",
            "Epoch: 1 | Iter: 5000 | Time: 00:01:07 | Train Loss: 2.5321 | Average Loss: 1.9653 \n",
            "Epoch: 1 | Iter: 6000 | Time: 00:01:20 | Train Loss: 1.6662 | Average Loss: 1.9584 \n",
            "Epoch: 1 | Iter: 7000 | Time: 00:01:34 | Train Loss: 2.6095 | Average Loss: 1.9515 \n",
            "Epoch: 1 | Iter: 8000 | Time: 00:01:47 | Train Loss: 2.2866 | Average Loss: 1.9408 \n",
            "Epoch: 1 | Iter: 9000 | Time: 00:02:00 | Train Loss: 1.6482 | Average Loss: 1.9354 \n",
            "Epoch: 1 | Iter:10000 | Time: 00:02:14 | Train Loss: 2.5226 | Average Loss: 1.9400 \n",
            "Epoch: 1 | Iter:11000 | Time: 00:02:27 | Train Loss: 1.2840 | Average Loss: 1.9359 \n",
            "Epoch: 1 | Iter:12000 | Time: 00:02:41 | Train Loss: 2.3167 | Average Loss: 1.9295 \n",
            "Accuracy: 0.344100 | Time: 00:00:12\n",
            "Epoch: 2 | Iter:    0 | Time: 00:03:00 | Train Loss: 1.4952 | Average Loss: 1.9261 \n",
            "Epoch: 2 | Iter: 1000 | Time: 00:03:13 | Train Loss: 1.1292 | Average Loss: 1.9205 \n",
            "Epoch: 2 | Iter: 2000 | Time: 00:03:27 | Train Loss: 1.7651 | Average Loss: 1.9161 \n",
            "Epoch: 2 | Iter: 3000 | Time: 00:03:40 | Train Loss: 1.3973 | Average Loss: 1.9101 \n",
            "Epoch: 2 | Iter: 4000 | Time: 00:03:54 | Train Loss: 1.8129 | Average Loss: 1.9037 \n",
            "Epoch: 2 | Iter: 5000 | Time: 00:04:07 | Train Loss: 1.6891 | Average Loss: 1.9003 \n",
            "Epoch: 2 | Iter: 6000 | Time: 00:04:21 | Train Loss: 1.9465 | Average Loss: 1.8957 \n",
            "Epoch: 2 | Iter: 7000 | Time: 00:04:34 | Train Loss: 2.3509 | Average Loss: 1.8900 \n",
            "Epoch: 2 | Iter: 8000 | Time: 00:04:48 | Train Loss: 1.9122 | Average Loss: 1.8862 \n",
            "Epoch: 2 | Iter: 9000 | Time: 00:05:01 | Train Loss: 1.4959 | Average Loss: 1.8850 \n",
            "Epoch: 2 | Iter:10000 | Time: 00:05:15 | Train Loss: 2.5291 | Average Loss: 1.8832 \n",
            "Epoch: 2 | Iter:11000 | Time: 00:05:28 | Train Loss: 2.4136 | Average Loss: 1.8808 \n",
            "Epoch: 2 | Iter:12000 | Time: 00:05:42 | Train Loss: 2.3721 | Average Loss: 1.8780 \n",
            "Accuracy: 0.366900 | Time: 00:00:12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgNqmNKbe7v7",
        "outputId": "e0339489-32a5-46e2-e1ca-f426b45e5fcf"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "acc = 0.0\n",
        "count = 0\n",
        "start_time = time.time()\n",
        "device = 'gpu' if next(model.parameters()).is_cuda else 'cpu'\n",
        "model.eval()\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "  for iter, (x, y) in enumerate(testloader):\n",
        "        count += x.shape[0]\n",
        "        batch_x = Variable(x).float()\n",
        "        batch_y = Variable(y).long()\n",
        "        if device == 'gpu':\n",
        "          batch_x = batch_x.cuda()\n",
        "          batch_y = batch_y.cuda()\n",
        "        outputs = model(batch_x)\n",
        "        # calculate outputs by running images through the network\n",
        "        #outputs = model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += batch_y.size(0)\n",
        "        correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 36 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYNc7x_Bhmlh",
        "outputId": "dae8b42f-0ce8-45d2-fe9d-8408f2e75e88"
      },
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "acc = 0.0\n",
        "count = 0\n",
        "start_time = time.time()\n",
        "device = 'gpu' if next(model.parameters()).is_cuda else 'cpu'\n",
        "model.eval()\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "   for iter, (x, y) in enumerate(testloader):\n",
        "        count += x.shape[0]\n",
        "        batch_x = Variable(x).float()\n",
        "        batch_y = Variable(y).long()\n",
        "        if device == 'gpu':\n",
        "          batch_x = batch_x.cuda()\n",
        "          batch_y = batch_y.cuda()\n",
        "        outputs = model(batch_x)\n",
        "        # calculate outputs by running images through the network\n",
        "        #outputs = model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "    \n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(batch_y, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
        "                                                   accuracy))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for class plane is: 0.0 %\n",
            "Accuracy for class car   is: 26.0 %\n",
            "Accuracy for class bird  is: 0.0 %\n",
            "Accuracy for class cat   is: 25.2 %\n",
            "Accuracy for class deer  is: 0.0 %\n",
            "Accuracy for class dog   is: 0.0 %\n",
            "Accuracy for class frog  is: 22.8 %\n",
            "Accuracy for class horse is: 25.6 %\n",
            "Accuracy for class ship  is: 0.0 %\n",
            "Accuracy for class truck is: 0.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9EWJDA3iJ7J"
      },
      "source": [
        "######################### Feature Extraction ####################3\n",
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model_conv.fc = nn.Linear(512,10)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtV7SBqkiRyf",
        "outputId": "dcee4a8d-731a-47f6-f6e5-2b449760929f"
      },
      "source": [
        "net = model_conv\n",
        "train_option = {}\n",
        "train_option['lr'] = 0.002\n",
        "train_option['epoch'] = 2\n",
        "train_option['device'] = 'gpu'\n",
        "train_option['optimizer'] = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "model = trainModel(net, trainloader, train_option, testloader)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Iter:    0 | Time: 00:00:00 | Train Loss: 2.9948 | Average Loss: 2.9948 \n",
            "Epoch: 1 | Iter: 1000 | Time: 00:00:06 | Train Loss: 22.2760 | Average Loss: 16.2597 \n",
            "Epoch: 1 | Iter: 2000 | Time: 00:00:12 | Train Loss: 23.0706 | Average Loss: 17.7665 \n",
            "Epoch: 1 | Iter: 3000 | Time: 00:00:18 | Train Loss: 11.3691 | Average Loss: 18.3549 \n",
            "Epoch: 1 | Iter: 4000 | Time: 00:00:24 | Train Loss: 6.9758 | Average Loss: 18.7525 \n",
            "Epoch: 1 | Iter: 5000 | Time: 00:00:30 | Train Loss: 9.4908 | Average Loss: 19.0309 \n",
            "Epoch: 1 | Iter: 6000 | Time: 00:00:36 | Train Loss: 22.4392 | Average Loss: 19.1761 \n",
            "Epoch: 1 | Iter: 7000 | Time: 00:00:42 | Train Loss: 6.3635 | Average Loss: 19.3364 \n",
            "Epoch: 1 | Iter: 8000 | Time: 00:00:48 | Train Loss: 29.1681 | Average Loss: 19.5572 \n",
            "Epoch: 1 | Iter: 9000 | Time: 00:00:54 | Train Loss: 18.4961 | Average Loss: 19.6452 \n",
            "Epoch: 1 | Iter:10000 | Time: 00:01:00 | Train Loss: 10.8940 | Average Loss: 19.7351 \n",
            "Epoch: 1 | Iter:11000 | Time: 00:01:06 | Train Loss: 31.1983 | Average Loss: 19.7905 \n",
            "Epoch: 1 | Iter:12000 | Time: 00:01:12 | Train Loss: 49.6733 | Average Loss: 19.8763 \n",
            "Accuracy: 0.206000 | Time: 00:00:10\n",
            "Epoch: 2 | Iter:    0 | Time: 00:01:26 | Train Loss: 18.6167 | Average Loss: 19.9180 \n",
            "Epoch: 2 | Iter: 1000 | Time: 00:01:32 | Train Loss: 35.3788 | Average Loss: 19.8982 \n",
            "Epoch: 2 | Iter: 2000 | Time: 00:01:38 | Train Loss: 29.8512 | Average Loss: 19.9420 \n",
            "Epoch: 2 | Iter: 3000 | Time: 00:01:44 | Train Loss: 22.9610 | Average Loss: 19.9627 \n",
            "Epoch: 2 | Iter: 4000 | Time: 00:01:50 | Train Loss: 26.0613 | Average Loss: 19.9834 \n",
            "Epoch: 2 | Iter: 5000 | Time: 00:01:56 | Train Loss: 10.0058 | Average Loss: 20.0297 \n",
            "Epoch: 2 | Iter: 6000 | Time: 00:02:02 | Train Loss: 16.0191 | Average Loss: 20.0524 \n",
            "Epoch: 2 | Iter: 7000 | Time: 00:02:08 | Train Loss: 15.5682 | Average Loss: 20.0726 \n",
            "Epoch: 2 | Iter: 8000 | Time: 00:02:14 | Train Loss: 21.5585 | Average Loss: 20.1141 \n",
            "Epoch: 2 | Iter: 9000 | Time: 00:02:20 | Train Loss: 12.3414 | Average Loss: 20.1077 \n",
            "Epoch: 2 | Iter:10000 | Time: 00:02:26 | Train Loss: 26.8276 | Average Loss: 20.1207 \n",
            "Epoch: 2 | Iter:11000 | Time: 00:02:32 | Train Loss: 30.9144 | Average Loss: 20.1227 \n",
            "Epoch: 2 | Iter:12000 | Time: 00:02:38 | Train Loss: 24.1001 | Average Loss: 20.1240 \n",
            "Accuracy: 0.209300 | Time: 00:00:10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNp11V9xiYX4",
        "outputId": "7a569d9a-b729-48b7-c060-01d75f590391"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "acc = 0.0\n",
        "count = 0\n",
        "start_time = time.time()\n",
        "device = 'gpu' if next(model.parameters()).is_cuda else 'cpu'\n",
        "model.eval()\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "  for iter, (x, y) in enumerate(testloader):\n",
        "        count += x.shape[0]\n",
        "        batch_x = Variable(x).float()\n",
        "        batch_y = Variable(y).long()\n",
        "        if device == 'gpu':\n",
        "          batch_x = batch_x.cuda()\n",
        "          batch_y = batch_y.cuda()\n",
        "        outputs = model(batch_x)\n",
        "        # calculate outputs by running images through the network\n",
        "        #outputs = model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += batch_y.size(0)\n",
        "        correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 20 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC96TI8Nia3o",
        "outputId": "57f1cdd9-0556-4333-8fe2-ae62b10dcb69"
      },
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "acc = 0.0\n",
        "count = 0\n",
        "start_time = time.time()\n",
        "device = 'gpu' if next(model.parameters()).is_cuda else 'cpu'\n",
        "model.eval()\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "   for iter, (x, y) in enumerate(testloader):\n",
        "        count += x.shape[0]\n",
        "        batch_x = Variable(x).float()\n",
        "        batch_y = Variable(y).long()\n",
        "        if device == 'gpu':\n",
        "          batch_x = batch_x.cuda()\n",
        "          batch_y = batch_y.cuda()\n",
        "        outputs = model(batch_x)\n",
        "        # calculate outputs by running images through the network\n",
        "        #outputs = model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "    \n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(batch_y, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
        "                                                   accuracy))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for class plane is: 0.0 %\n",
            "Accuracy for class car   is: 26.0 %\n",
            "Accuracy for class bird  is: 0.0 %\n",
            "Accuracy for class cat   is: 25.2 %\n",
            "Accuracy for class deer  is: 0.0 %\n",
            "Accuracy for class dog   is: 0.0 %\n",
            "Accuracy for class frog  is: 22.8 %\n",
            "Accuracy for class horse is: 25.6 %\n",
            "Accuracy for class ship  is: 0.0 %\n",
            "Accuracy for class truck is: 0.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}