{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Logistic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opc02qBWf5Zz"
      },
      "source": [
        "**CSE 512 Spring 2021 - Machine Learning - Homework 2**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Your Name: Irfan Ahmed \\\\\n",
        "Solar ID : 113166464 \\\\\n",
        "NetID Email: irfan.ahmed@stonybrook.edu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFDfiojH5EuK",
        "outputId": "3d23c4b2-7571-4d49-ff22-046fc9b3d225"
      },
      "source": [
        "# Mount your google drive where you've saved your assignment folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VONZ84tg42HW",
        "outputId": "2505e099-f1c5-4c22-cb7f-4e2c528831d4"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/Colab\\ Notebooks/CSE512_ML/HW2/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/CSE512_ML/HW2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGHSbVLH42Hj"
      },
      "source": [
        "import numpy as np\n",
        "import random \n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "from numba import jit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "01lJp7ED42Hk",
        "outputId": "ac773226-64e0-422f-e956-ff7add30c442"
      },
      "source": [
        "# Parameters :\n",
        "'''\n",
        "1. X -> column vector (d x 1)\n",
        "2. X_bar -> appending 1 at end ( d+1 x 1)\n",
        "3. theta_i -> (d+1 x 1) [ theta_1 to theta_k-1], theta (k-1 x d+1)\n",
        "4. W -> learned weight matrix ( k-1 x d), W_i is learned weight vector of theta_i\n",
        "5. b -> biases ( k-1 x 1 )\n",
        "6. X ->  test data ( n x d)\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n1. X -> column vector (d x 1)\\n2. X_bar -> appending 1 at end ( d+1 x 1)\\n3. theta_i -> (d+1 x 1) [ theta_1 to theta_k-1], theta (k-1 x d+1)\\n4. W -> learned weight matrix ( k-1 x d), W_i is learned weight vector of theta_i\\n5. b -> biases ( k-1 x 1 )\\n6. X ->  test data ( n x d)\\n\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP39z9eb42Hl"
      },
      "source": [
        "def logreg_predict_prob(W, b, X):\n",
        "    theta_transpose = np.append(W,b.reshape(-1,1), axis = 1)  # reshape b if necessary b.reshape(-1,1)\n",
        "    \n",
        "    # theta_transpose ( k-1 x d+1)\n",
        "    # append 1 to X -> X_bar (n x d+1)\n",
        "    X_bar  = np.append(X, np.ones((len(X),1)), axis = 1)\n",
        "    \n",
        "    P = np.zeros((len(X),len(theta_transpose) + 1)) # n x k\n",
        "    \n",
        "    for i in range(len(X)): # 1 to n\n",
        "        A = np.zeros(len(theta_transpose) + 1) # k\n",
        "        for j in range(len(W)): # 1 to k-1\n",
        "            # P (Y =j|X; theta_transpose) \n",
        "            A[j] = np.dot(theta_transpose[j],X_bar[i])\n",
        "        A = np.exp(A - np.max(A))\n",
        "        A = A/np.sum(A)\n",
        "        P[i] = A\n",
        "    \n",
        "    return P"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW6nM5Ew42Hm"
      },
      "source": [
        "def logreg_predict_class(W, b, X):\n",
        "    P = logreg_predict_prob(W, b, X)\n",
        "    y_hat = P.argmax(axis = 1).reshape(-1,1)\n",
        "    return y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy78kuq142Hm"
      },
      "source": [
        "def permute(end):\n",
        "    array = np.arange(end)\n",
        "    random.shuffle(array)\n",
        "    return array.astype(np.int)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieKzSuSe42Hm"
      },
      "source": [
        "def separate_theta_W_b(theta): # theta is k-1 x d+1\n",
        "    W = theta[:,:-1]\n",
        "    b = theta[:,-1].reshape(-1,1)\n",
        "    return W,b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXab6GnT42Hn"
      },
      "source": [
        "def loss_theta(X,y,theta):\n",
        "    W,b = separate_theta_W_b(theta)\n",
        "    P = logreg_predict_prob(W,b,X)\n",
        "    loss = 0.0 \n",
        "    for i in range(len(X)):\n",
        "            loss+= np.log(P[i,y[i]])\n",
        "\n",
        "    return (-1/len(X)) * loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN_u8Mkd42Hn"
      },
      "source": [
        "def gradient_descent(X,y,batch,theta):\n",
        "    \n",
        "    W,b = separate_theta_W_b(theta)\n",
        "    P = logreg_predict_prob(W,b,X)\n",
        "    result = np.zeros(theta.shape)\n",
        "    for i in range(len(theta)):\n",
        "        descent = np.zeros(X.shape[1] + 1) \n",
        "        for j in batch:\n",
        "            if(y[j] == i):\n",
        "                descent = descent +  (1 - P[j,i]) * (np.append(X[j],[1]))\n",
        "            else : \n",
        "                descent = descent + (0 - P[j,i]) * (np.append(X[j],[1]))\n",
        "        \n",
        "        result[i] = descent \n",
        "                             \n",
        "    return result* (-1/len(batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf16j83I42Ho"
      },
      "source": [
        "def logreg_fit(X, y, m, eta_start, eta_end, epsilon, max_epoch = 1000):\n",
        "    # permute\n",
        "    array = permute(len(X))\n",
        "    \n",
        "    # dividing into batches\n",
        "    batches = np.array_split(array,m)\n",
        "    \n",
        "    # obtain k-value\n",
        "    k = np.max(y) + 1 \n",
        "    d = X.shape[1] # no. of features\n",
        "    \n",
        "    theta = np.zeros((k-1,d+1))\n",
        "    Loss_list = []\n",
        "    eta = eta_start\n",
        "    \n",
        "    for epoch in range(max_epoch):\n",
        "        theta_old = theta\n",
        "        for batch in batches:\n",
        "            dL_dtheta = gradient_descent(X,y,batch,theta)\n",
        "            # update theta\n",
        "            theta = theta - eta*dL_dtheta\n",
        "        \n",
        "        loss_theta_old = loss_theta(X,y,theta_old)\n",
        "        loss_theta_current = loss_theta(X,y,theta) \n",
        "        Loss_list.append(loss_theta_current)\n",
        "        \n",
        "        if( (loss_theta_old - loss_theta_current) < (epsilon * loss_theta_old) ):\n",
        "            eta = eta/10\n",
        "        if(eta < eta_end):\n",
        "            break\n",
        "        print(\"\\nCompleted epoch: \" + str(epoch))\n",
        "    W,b = separate_theta_W_b(theta)\n",
        "    Loss_list = np.array(Loss_list)\n",
        "    return W,b,Loss_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frlLDReg42Hp"
      },
      "source": [
        "def get_data(path):\n",
        "    covid_data = pd.read_csv(path)\n",
        "    covid_data = covid_data.to_numpy()\n",
        "    X = covid_data[:,:-1].astype(np.float64)\n",
        "    y = covid_data[:,-1].astype(int)\n",
        "    return X,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vOob30k42Hp"
      },
      "source": [
        "def preprocess_data(X,Y):\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "    Y = scaler.transform(Y)\n",
        "    \n",
        "    return X,Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoJPhiC442Hp",
        "outputId": "085c1e58-0bd4-433d-9bad-25e52afdbbaf"
      },
      "source": [
        "X_train, y_train = get_data('train.csv')\n",
        "X_test, y_test = get_data('test.csv')\n",
        "\n",
        "X_train, X_test = preprocess_data(X_train,X_test)\n",
        "\n",
        "print(len(X_train[0]))\n",
        "print(X_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "95\n",
            "[[-0.99350877  1.40401609 -0.0895731  ... -0.83658652 -0.65059586\n",
            "   1.1891063 ]\n",
            " [-0.99350877  1.40401609 -0.0895731  ... -0.83658652 -0.65059586\n",
            "   1.1891063 ]\n",
            " [-0.99350877  1.40401609 -0.0895731  ... -0.83658652 -0.65059586\n",
            "   1.1891063 ]\n",
            " ...\n",
            " [-0.99350877  2.01557903 -0.0895731  ... -0.83658652  1.53705251\n",
            "  -0.84096771]\n",
            " [-0.99350877  2.07117566 -0.0895731  ... -0.83658652 -0.65059586\n",
            "   1.1891063 ]\n",
            " [-0.99350877  2.12677229 -0.0895731  ... -0.83658652 -0.65059586\n",
            "   1.1891063 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QathH60H6Fzj"
      },
      "source": [
        "**Running the model to fit our training set.**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9j8EBYp42Hq",
        "outputId": "2eb092a3-b127-4412-ee05-b6f6ff137318"
      },
      "source": [
        "# logreg_fit(X, y, m, eta_start, eta_end, epsilon, max_epoch = 1000):\n",
        "W,b,Loss_list = logreg_fit(X_train, y_train, 256, 0.01, 0.00001, 0.0001,10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Completed epoch: 0\n",
            "\n",
            "Completed epoch: 1\n",
            "\n",
            "Completed epoch: 2\n",
            "\n",
            "Completed epoch: 3\n",
            "\n",
            "Completed epoch: 4\n",
            "\n",
            "Completed epoch: 5\n",
            "\n",
            "Completed epoch: 6\n",
            "\n",
            "Completed epoch: 7\n",
            "\n",
            "Completed epoch: 8\n",
            "\n",
            "Completed epoch: 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRn5C9Bi6O8V"
      },
      "source": [
        "**Plotting the Loss function**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "Q2-9IK2C42Hr",
        "outputId": "30ae8539-b30e-4702-8608-04832d41e9c8"
      },
      "source": [
        "plot_x = np.arange(len(Loss_list))\n",
        "print(plot_x)\n",
        "print(Loss_list)\n",
        "plot_y = Loss_list \n",
        "plt.xlabel('# of epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(plot_x,plot_y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "[0.37995643 0.28324529 0.23867009 0.21395191 0.19847911 0.18794603\n",
            " 0.18032802 0.17456329 0.17004653 0.16640926]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNfWac4p5gxC"
      },
      "source": [
        "2.3.c) The values of hyperparameters chosen are \n",
        "eta_start = 0.1(Increased), m = 512(Doubled) eta_end = 0.00001, max_epochs = 40. \n",
        "\n",
        "Training Data : \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Accuracy Score: 0.9439218523878437\n",
        "*   Accuracy from confusion matrix: 0.7551306966844182\n",
        "\n",
        "\n",
        "\n",
        "Testing Data :\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*   Accuracy Score: 0.9117221418234442\n",
        "*   Accuracy from confusion matrix: 0.6426040494938133\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "With these new values, the number of epochs taken to converge is around 40 and same accuracy with original values. \n",
        "Reasoning behind chosing these values comes from 2.3.b,where increasing eta and increasing m maintained same accuracy but converged faster. Hence the early stopping was identified and used in this hyperparameters. \n",
        "\n",
        "Other approaches such as Grid search and Random search can be used for hyperparameter optimisation but the computations are taking a toll. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xya9bNBaEzg"
      },
      "source": [
        "2.3.2.b)Increasing (eta_start)learning rate(0.1), decreases my loss function faster and converges earlier (at 30). The accuracy on testing data increased to 91.7% (earlier 90.5%). \n",
        "Decreasing learning rate(0.001), increases no of epochs to converge. The accuracy remains same with slight difference. \n",
        "\n",
        "\n",
        "Decreasing batch size(100) decreases convergence rate of my loss function and the epochs have increased. Final performance is lowered a little bit. Increasing batch size(doubled now) maintained the same final performance but the loss converged at 30 epochs(earlier). \n",
        "\n",
        "Increasing eta_end, increases the no of epochs keeping the performance nearly same as original params. It looks like the model reaches the same performance but slowly.\n",
        "\n",
        "Decreasing max epochs (<20) does not coverge the loss function. Increasing the max epochs gives no meaning as loss converges and no point in training further. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-Ibm4NpVoa8"
      },
      "source": [
        "Without feature normalization, the model is increasing in loss and then converging. The number of epochs have reduced are now being dependent on eta_start and eta_end. It implies that the loss is not converging but decreasing the learning rate in this regard. Changing eta_end to 10^-12 shows loss has increased to a certain level and converged there. The final performance of the model has been decreased but nothing significant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoqREiTkSfzl"
      },
      "source": [
        "With increasing epochs, the loss function converges to a constant value and does not increase or decrease much from the previous value. From the graph it can be observed that beyond 40 epochs, there is no use training the model further as the loss has converged.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWEPoj146j-2"
      },
      "source": [
        "**Obtain Predictions for Training and Testing Data**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmdneih142Hs"
      },
      "source": [
        "y_train_pred = logreg_predict_class(W,b,X_train)\n",
        "y_test_pred = logreg_predict_class(W,b,X_test) \n",
        "\n",
        "#print(y_test_pred.reshape(1,-1))\n",
        "#print(y_test.reshape(1,-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xJ8U-Yn6tAc"
      },
      "source": [
        "***Performance Metrics***\n",
        "\n",
        "\n",
        "*   Accuracy\n",
        "*   Confusion Matrix\n",
        "*   Accuracy from Confusion Matrix\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHPf3xUv42Ht"
      },
      "source": [
        "def report_results(y,y_hat):\n",
        "    accuracy_metric = accuracy_score(y, y_hat)\n",
        "    confusion = confusion_matrix(y, y_hat, normalize = 'true')\n",
        "    trace_CM = np.trace(confusion)\n",
        "    total_population = np.sum(confusion)\n",
        "    accuracy = trace_CM/total_population\n",
        "    \n",
        "    print(\"\\nPerformance Metrics:\")\n",
        "    print(\"\\nAccuracy Score:\" + str(accuracy_metric))\n",
        "\n",
        "    print(\"\\n Confusion Matrix : \")\n",
        "    print(confusion)\n",
        "\n",
        "    print(\"\\n Accuracy from confusion matrix:\" + str(accuracy))\n",
        "\n",
        "    #return accuracy_metric, confusion, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cogfqw3X42Hv",
        "outputId": "018634bb-ed6d-461c-9528-5d2665896c7b"
      },
      "source": [
        "print(\"----------Training Data----------\\n\")\n",
        "report_results(y_train,y_train_pred)\n",
        "\n",
        "print(\"----------Testing Data----------\\n\")\n",
        "report_results(y_test,y_test_pred)\n",
        "\n",
        "#report_results(y_train,y_train_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------Training Data----------\n",
            "\n",
            "\n",
            "Performance Metrics:\n",
            "\n",
            "Accuracy Score:0.9417510853835022\n",
            "\n",
            " Confusion Matrix : \n",
            "[[0.98457888 0.01542112]\n",
            " [0.51914894 0.48085106]]\n",
            "\n",
            " Accuracy from confusion matrix:0.7327149743822721\n",
            "----------Testing Data----------\n",
            "\n",
            "\n",
            "Performance Metrics:\n",
            "\n",
            "Accuracy Score:0.91027496382055\n",
            "\n",
            " Confusion Matrix : \n",
            "[[0.97007874 0.02992126]\n",
            " [0.76785714 0.23214286]]\n",
            "\n",
            " Accuracy from confusion matrix:0.6011107986501687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szpFhgwf42Hv"
      },
      "source": [
        "def avg_precision_and_precision_recall_curve(X,y,W,b):\n",
        "    P = logreg_predict_prob(W, b, np.array(X))\n",
        "    y_score = []\n",
        "    #X = [X[i] for i in range(X.shape[0]) if y[i] == 1]\n",
        "    #y_score = logreg_predict_class(W,b,X)\n",
        "    for i in range(len(X)):\n",
        "      y_score.append(P[i,1])\n",
        "\n",
        "    \n",
        "    #y = [y[i] for i in range(len(y)) if y[i] == 1] \n",
        "    #y_score = [y_score[i] for i in range(len(y)) if y[i] == 1 ]\n",
        "    #print(accuracy_score(y,y_score))\n",
        "    #print(y_score)\n",
        "    y,y_score = np.array(y), np.array(y_score,dtype=np.float32)\n",
        "    y = y.flatten()\n",
        "    y_score = y_score.flatten()\n",
        "\n",
        "    avg_prec_score = average_precision_score(y, y_score)\n",
        "    precision, recall, thresholds = precision_recall_curve(y, y_score)\n",
        "\n",
        "    #precision = [precision[i] for i in range(len(y)-1) if y[i] == 1]\n",
        "    #recall = [recall[i] for i in range(len(y)-1) if y[i] == 1]\n",
        "    \n",
        "    print(\"Average Precision Score: \" + str(avg_prec_score))\n",
        "    \n",
        "    \n",
        "    plt.plot(recall, precision)\n",
        "    plt.xlabel('Recall (Positive label : 1)')\n",
        "    plt.ylabel('Precision (Positive label : 1)')\n",
        "    plt.show()\n",
        "    \n",
        "    #disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
        "    #disp.plot() \n",
        "    \n",
        "\n",
        "    return avg_prec_score, precision, recall, thresholds\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wl0Zic2642Hw",
        "outputId": "64fa4866-51fc-437b-8f4d-417f940df59e"
      },
      "source": [
        "avg_precision_and_precision_recall_curve(X_test,y_test,W,b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Precision Score: 0.31201202916949466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.31201202916949466,\n",
              " array([0.08358209, 0.08221226, 0.08233533, 0.08245877, 0.08258258,\n",
              "        0.08270677, 0.08283133, 0.08295626, 0.08308157, 0.08320726,\n",
              "        0.08333333, 0.08345979, 0.08358663, 0.08371385, 0.08384146,\n",
              "        0.08396947, 0.08409786, 0.08422665, 0.08435583, 0.08448541,\n",
              "        0.08461538, 0.08474576, 0.08487654, 0.08500773, 0.08513932,\n",
              "        0.08527132, 0.08540373, 0.08553655, 0.08566978, 0.08580343,\n",
              "        0.0859375 , 0.08607199, 0.0862069 , 0.08634223, 0.08647799,\n",
              "        0.08661417, 0.08675079, 0.08688784, 0.08702532, 0.08716323,\n",
              "        0.08730159, 0.08744038, 0.08757962, 0.0877193 , 0.08785942,\n",
              "        0.088     , 0.08814103, 0.0882825 , 0.08842444, 0.08856683,\n",
              "        0.08870968, 0.08885299, 0.08899676, 0.089141  , 0.08928571,\n",
              "        0.08943089, 0.08957655, 0.08972268, 0.08986928, 0.09001637,\n",
              "        0.09016393, 0.09031199, 0.09046053, 0.09060956, 0.09075908,\n",
              "        0.09090909, 0.0910596 , 0.09121061, 0.09136213, 0.09151414,\n",
              "        0.09166667, 0.0918197 , 0.09197324, 0.0921273 , 0.09228188,\n",
              "        0.09243697, 0.09259259, 0.09274874, 0.09290541, 0.09306261,\n",
              "        0.09322034, 0.09337861, 0.09353741, 0.09369676, 0.09385666,\n",
              "        0.09401709, 0.09417808, 0.09433962, 0.09450172, 0.09466437,\n",
              "        0.09482759, 0.09499136, 0.09342561, 0.09358752, 0.09375   ,\n",
              "        0.09391304, 0.09233449, 0.09249564, 0.09265734, 0.09281961,\n",
              "        0.09298246, 0.09314587, 0.09330986, 0.09347443, 0.09363958,\n",
              "        0.09380531, 0.09397163, 0.09413854, 0.09430605, 0.09447415,\n",
              "        0.09464286, 0.09481216, 0.09498208, 0.0951526 , 0.09532374,\n",
              "        0.0954955 , 0.09566787, 0.09584087, 0.09601449, 0.09618875,\n",
              "        0.09636364, 0.09653916, 0.09671533, 0.09689214, 0.0952381 ,\n",
              "        0.09541284, 0.09558824, 0.09576427, 0.09594096, 0.0961183 ,\n",
              "        0.0962963 , 0.09647495, 0.09665428, 0.09683426, 0.09701493,\n",
              "        0.09719626, 0.09737828, 0.09756098, 0.09774436, 0.09792844,\n",
              "        0.09811321, 0.09829868, 0.09848485, 0.09867173, 0.09885932,\n",
              "        0.09904762, 0.09923664, 0.09942639, 0.09961686, 0.09980806,\n",
              "        0.1       , 0.10019268, 0.1003861 , 0.10058027, 0.10077519,\n",
              "        0.10097087, 0.10116732, 0.10136452, 0.1015625 , 0.10176125,\n",
              "        0.10196078, 0.1021611 , 0.1023622 , 0.1025641 , 0.1027668 ,\n",
              "        0.1029703 , 0.1031746 , 0.10337972, 0.10358566, 0.10379242,\n",
              "        0.104     , 0.10420842, 0.10441767, 0.10462777, 0.10483871,\n",
              "        0.10505051, 0.10526316, 0.10547667, 0.10569106, 0.10590631,\n",
              "        0.10612245, 0.10633947, 0.10655738, 0.10677618, 0.10699588,\n",
              "        0.10721649, 0.10743802, 0.10766046, 0.10788382, 0.10810811,\n",
              "        0.10625   , 0.10647182, 0.10669456, 0.10691824, 0.10714286,\n",
              "        0.10736842, 0.10759494, 0.10782241, 0.10805085, 0.10615711,\n",
              "        0.10638298, 0.10660981, 0.10683761, 0.10706638, 0.10729614,\n",
              "        0.10752688, 0.10775862, 0.10799136, 0.10822511, 0.10845987,\n",
              "        0.10869565, 0.10893246, 0.10917031, 0.10940919, 0.10964912,\n",
              "        0.10989011, 0.11013216, 0.11037528, 0.11061947, 0.11086475,\n",
              "        0.11111111, 0.11135857, 0.109375  , 0.10961969, 0.10986547,\n",
              "        0.11011236, 0.11036036, 0.11060948, 0.11085973, 0.11111111,\n",
              "        0.11136364, 0.11161731, 0.11187215, 0.11212815, 0.11238532,\n",
              "        0.11264368, 0.11290323, 0.11316397, 0.11342593, 0.1136891 ,\n",
              "        0.11395349, 0.11421911, 0.11448598, 0.1147541 , 0.11502347,\n",
              "        0.11529412, 0.11556604, 0.11583924, 0.11611374, 0.11638955,\n",
              "        0.11666667, 0.11455847, 0.11483254, 0.11510791, 0.11538462,\n",
              "        0.11566265, 0.11594203, 0.11622276, 0.11650485, 0.11678832,\n",
              "        0.11707317, 0.11735941, 0.11764706, 0.11793612, 0.1182266 ,\n",
              "        0.11851852, 0.11881188, 0.1191067 , 0.11940299, 0.11970075,\n",
              "        0.12      , 0.12030075, 0.12060302, 0.1209068 , 0.12121212,\n",
              "        0.12151899, 0.12182741, 0.1221374 , 0.12244898, 0.12276215,\n",
              "        0.12307692, 0.12339332, 0.12371134, 0.12403101, 0.12435233,\n",
              "        0.12467532, 0.125     , 0.12532637, 0.12303665, 0.12335958,\n",
              "        0.12368421, 0.12401055, 0.12433862, 0.12201592, 0.12234043,\n",
              "        0.12266667, 0.12299465, 0.1233244 , 0.12365591, 0.12398922,\n",
              "        0.12432432, 0.12466125, 0.125     , 0.1253406 , 0.12568306,\n",
              "        0.1260274 , 0.12637363, 0.12672176, 0.12707182, 0.12742382,\n",
              "        0.12777778, 0.1281337 , 0.12849162, 0.12885154, 0.12921348,\n",
              "        0.12957746, 0.12711864, 0.12747875, 0.12784091, 0.12820513,\n",
              "        0.12857143, 0.12893983, 0.12931034, 0.129683  , 0.1300578 ,\n",
              "        0.13043478, 0.13081395, 0.13119534, 0.13157895, 0.13196481,\n",
              "        0.12941176, 0.12979351, 0.13017751, 0.1305638 , 0.13095238,\n",
              "        0.13134328, 0.13173653, 0.13213213, 0.13253012, 0.13293051,\n",
              "        0.13333333, 0.1337386 , 0.13414634, 0.13455657, 0.13496933,\n",
              "        0.13538462, 0.13580247, 0.13312693, 0.13354037, 0.13395639,\n",
              "        0.134375  , 0.13479624, 0.13522013, 0.13564669, 0.13607595,\n",
              "        0.13650794, 0.13694268, 0.13738019, 0.13782051, 0.13826367,\n",
              "        0.13870968, 0.13915858, 0.13961039, 0.14006515, 0.14052288,\n",
              "        0.14098361, 0.14144737, 0.14191419, 0.14238411, 0.14285714,\n",
              "        0.14333333, 0.14381271, 0.1442953 , 0.14478114, 0.14527027,\n",
              "        0.14576271, 0.1462585 , 0.14675768, 0.14726027, 0.14776632,\n",
              "        0.14827586, 0.14878893, 0.14930556, 0.14982578, 0.15034965,\n",
              "        0.15087719, 0.15140845, 0.15194346, 0.15248227, 0.15302491,\n",
              "        0.15357143, 0.15412186, 0.15467626, 0.15162455, 0.15217391,\n",
              "        0.15272727, 0.15328467, 0.15384615, 0.15441176, 0.15498155,\n",
              "        0.15555556, 0.15613383, 0.15671642, 0.15730337, 0.15789474,\n",
              "        0.15849057, 0.15909091, 0.15969582, 0.16030534, 0.16091954,\n",
              "        0.16153846, 0.16216216, 0.1627907 , 0.16342412, 0.1640625 ,\n",
              "        0.16470588, 0.16535433, 0.16600791, 0.16666667, 0.16733068,\n",
              "        0.168     , 0.1686747 , 0.16935484, 0.17004049, 0.17073171,\n",
              "        0.17142857, 0.17213115, 0.17283951, 0.17355372, 0.17427386,\n",
              "        0.175     , 0.17573222, 0.17647059, 0.17721519, 0.1779661 ,\n",
              "        0.1787234 , 0.17948718, 0.18025751, 0.18103448, 0.18181818,\n",
              "        0.1826087 , 0.18340611, 0.18421053, 0.18502203, 0.18584071,\n",
              "        0.18666667, 0.1875    , 0.18834081, 0.18918919, 0.19004525,\n",
              "        0.18636364, 0.18721461, 0.18807339, 0.18894009, 0.18981481,\n",
              "        0.19069767, 0.19158879, 0.19248826, 0.19339623, 0.1943128 ,\n",
              "        0.1952381 , 0.19617225, 0.19711538, 0.19806763, 0.19902913,\n",
              "        0.2       , 0.20098039, 0.20197044, 0.2029703 , 0.2039801 ,\n",
              "        0.205     , 0.20603015, 0.20707071, 0.20812183, 0.20918367,\n",
              "        0.21025641, 0.21134021, 0.21243523, 0.21354167, 0.21465969,\n",
              "        0.21578947, 0.21693122, 0.21276596, 0.21390374, 0.21505376,\n",
              "        0.21621622, 0.2173913 , 0.21857923, 0.21978022, 0.22099448,\n",
              "        0.22222222, 0.22346369, 0.2247191 , 0.2259887 , 0.22727273,\n",
              "        0.22857143, 0.22988506, 0.23121387, 0.23255814, 0.23391813,\n",
              "        0.23529412, 0.23668639, 0.23809524, 0.23952096, 0.23493976,\n",
              "        0.23636364, 0.23780488, 0.23312883, 0.2345679 , 0.23602484,\n",
              "        0.2375    , 0.23899371, 0.23417722, 0.23566879, 0.23717949,\n",
              "        0.23870968, 0.24025974, 0.24183007, 0.24342105, 0.24503311,\n",
              "        0.24666667, 0.24832215, 0.25      , 0.25170068, 0.25342466,\n",
              "        0.25517241, 0.25694444, 0.25874126, 0.26056338, 0.26241135,\n",
              "        0.26428571, 0.26618705, 0.26811594, 0.26277372, 0.26470588,\n",
              "        0.26666667, 0.26865672, 0.27067669, 0.27272727, 0.27480916,\n",
              "        0.27692308, 0.27906977, 0.28125   , 0.28346457, 0.28571429,\n",
              "        0.288     , 0.29032258, 0.29268293, 0.29508197, 0.29752066,\n",
              "        0.3       , 0.30252101, 0.30508475, 0.30769231, 0.30172414,\n",
              "        0.29565217, 0.29824561, 0.30088496, 0.30357143, 0.30630631,\n",
              "        0.30909091, 0.31192661, 0.31481481, 0.31775701, 0.32075472,\n",
              "        0.32380952, 0.32692308, 0.33009709, 0.33333333, 0.32673267,\n",
              "        0.32      , 0.32323232, 0.32653061, 0.32989691, 0.33333333,\n",
              "        0.33684211, 0.32978723, 0.33333333, 0.32608696, 0.32967033,\n",
              "        0.33333333, 0.33707865, 0.34090909, 0.34482759, 0.34883721,\n",
              "        0.35294118, 0.35714286, 0.36144578, 0.35365854, 0.35802469,\n",
              "        0.3625    , 0.36708861, 0.37179487, 0.37662338, 0.36842105,\n",
              "        0.37333333, 0.37837838, 0.36986301, 0.375     , 0.36619718,\n",
              "        0.37142857, 0.37681159, 0.38235294, 0.3880597 , 0.37878788,\n",
              "        0.36923077, 0.375     , 0.38095238, 0.38709677, 0.39344262,\n",
              "        0.4       , 0.40677966, 0.4137931 , 0.42105263, 0.41071429,\n",
              "        0.4       , 0.40740741, 0.41509434, 0.42307692, 0.43137255,\n",
              "        0.42      , 0.42857143, 0.41666667, 0.40425532, 0.41304348,\n",
              "        0.4       , 0.38636364, 0.37209302, 0.35714286, 0.36585366,\n",
              "        0.375     , 0.38461538, 0.39473684, 0.37837838, 0.36111111,\n",
              "        0.37142857, 0.38235294, 0.39393939, 0.40625   , 0.41935484,\n",
              "        0.4       , 0.37931034, 0.35714286, 0.37037037, 0.38461538,\n",
              "        0.4       , 0.41666667, 0.43478261, 0.45454545, 0.42857143,\n",
              "        0.4       , 0.36842105, 0.38888889, 0.41176471, 0.375     ,\n",
              "        0.33333333, 0.35714286, 0.38461538, 0.33333333, 0.36363636,\n",
              "        0.4       , 0.33333333, 0.375     , 0.42857143, 0.33333333,\n",
              "        0.2       , 0.25      , 0.33333333, 0.5       , 1.        ,\n",
              "        1.        ]),\n",
              " array([1.        , 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.98214286, 0.98214286, 0.98214286,\n",
              "        0.98214286, 0.98214286, 0.96428571, 0.96428571, 0.96428571,\n",
              "        0.96428571, 0.94642857, 0.94642857, 0.94642857, 0.94642857,\n",
              "        0.94642857, 0.94642857, 0.94642857, 0.94642857, 0.94642857,\n",
              "        0.94642857, 0.94642857, 0.94642857, 0.94642857, 0.94642857,\n",
              "        0.94642857, 0.94642857, 0.94642857, 0.94642857, 0.94642857,\n",
              "        0.94642857, 0.94642857, 0.94642857, 0.94642857, 0.94642857,\n",
              "        0.94642857, 0.94642857, 0.94642857, 0.94642857, 0.92857143,\n",
              "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
              "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
              "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
              "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
              "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
              "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
              "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
              "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
              "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
              "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
              "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
              "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
              "        0.92857143, 0.92857143, 0.92857143, 0.92857143, 0.92857143,\n",
              "        0.91071429, 0.91071429, 0.91071429, 0.91071429, 0.91071429,\n",
              "        0.91071429, 0.91071429, 0.91071429, 0.91071429, 0.89285714,\n",
              "        0.89285714, 0.89285714, 0.89285714, 0.89285714, 0.89285714,\n",
              "        0.89285714, 0.89285714, 0.89285714, 0.89285714, 0.89285714,\n",
              "        0.89285714, 0.89285714, 0.89285714, 0.89285714, 0.89285714,\n",
              "        0.89285714, 0.89285714, 0.89285714, 0.89285714, 0.89285714,\n",
              "        0.89285714, 0.89285714, 0.875     , 0.875     , 0.875     ,\n",
              "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ,\n",
              "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ,\n",
              "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ,\n",
              "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ,\n",
              "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ,\n",
              "        0.875     , 0.85714286, 0.85714286, 0.85714286, 0.85714286,\n",
              "        0.85714286, 0.85714286, 0.85714286, 0.85714286, 0.85714286,\n",
              "        0.85714286, 0.85714286, 0.85714286, 0.85714286, 0.85714286,\n",
              "        0.85714286, 0.85714286, 0.85714286, 0.85714286, 0.85714286,\n",
              "        0.85714286, 0.85714286, 0.85714286, 0.85714286, 0.85714286,\n",
              "        0.85714286, 0.85714286, 0.85714286, 0.85714286, 0.85714286,\n",
              "        0.85714286, 0.85714286, 0.85714286, 0.85714286, 0.85714286,\n",
              "        0.85714286, 0.85714286, 0.85714286, 0.83928571, 0.83928571,\n",
              "        0.83928571, 0.83928571, 0.83928571, 0.82142857, 0.82142857,\n",
              "        0.82142857, 0.82142857, 0.82142857, 0.82142857, 0.82142857,\n",
              "        0.82142857, 0.82142857, 0.82142857, 0.82142857, 0.82142857,\n",
              "        0.82142857, 0.82142857, 0.82142857, 0.82142857, 0.82142857,\n",
              "        0.82142857, 0.82142857, 0.82142857, 0.82142857, 0.82142857,\n",
              "        0.82142857, 0.80357143, 0.80357143, 0.80357143, 0.80357143,\n",
              "        0.80357143, 0.80357143, 0.80357143, 0.80357143, 0.80357143,\n",
              "        0.80357143, 0.80357143, 0.80357143, 0.80357143, 0.80357143,\n",
              "        0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
              "        0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
              "        0.78571429, 0.78571429, 0.78571429, 0.78571429, 0.78571429,\n",
              "        0.78571429, 0.78571429, 0.76785714, 0.76785714, 0.76785714,\n",
              "        0.76785714, 0.76785714, 0.76785714, 0.76785714, 0.76785714,\n",
              "        0.76785714, 0.76785714, 0.76785714, 0.76785714, 0.76785714,\n",
              "        0.76785714, 0.76785714, 0.76785714, 0.76785714, 0.76785714,\n",
              "        0.76785714, 0.76785714, 0.76785714, 0.76785714, 0.76785714,\n",
              "        0.76785714, 0.76785714, 0.76785714, 0.76785714, 0.76785714,\n",
              "        0.76785714, 0.76785714, 0.76785714, 0.76785714, 0.76785714,\n",
              "        0.76785714, 0.76785714, 0.76785714, 0.76785714, 0.76785714,\n",
              "        0.76785714, 0.76785714, 0.76785714, 0.76785714, 0.76785714,\n",
              "        0.76785714, 0.76785714, 0.76785714, 0.75      , 0.75      ,\n",
              "        0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
              "        0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
              "        0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
              "        0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
              "        0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
              "        0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
              "        0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
              "        0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
              "        0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
              "        0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
              "        0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
              "        0.73214286, 0.73214286, 0.73214286, 0.73214286, 0.73214286,\n",
              "        0.73214286, 0.73214286, 0.73214286, 0.73214286, 0.73214286,\n",
              "        0.73214286, 0.73214286, 0.73214286, 0.73214286, 0.73214286,\n",
              "        0.73214286, 0.73214286, 0.73214286, 0.73214286, 0.73214286,\n",
              "        0.73214286, 0.73214286, 0.73214286, 0.73214286, 0.73214286,\n",
              "        0.73214286, 0.73214286, 0.73214286, 0.73214286, 0.73214286,\n",
              "        0.73214286, 0.73214286, 0.71428571, 0.71428571, 0.71428571,\n",
              "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
              "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
              "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
              "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.69642857,\n",
              "        0.69642857, 0.69642857, 0.67857143, 0.67857143, 0.67857143,\n",
              "        0.67857143, 0.67857143, 0.66071429, 0.66071429, 0.66071429,\n",
              "        0.66071429, 0.66071429, 0.66071429, 0.66071429, 0.66071429,\n",
              "        0.66071429, 0.66071429, 0.66071429, 0.66071429, 0.66071429,\n",
              "        0.66071429, 0.66071429, 0.66071429, 0.66071429, 0.66071429,\n",
              "        0.66071429, 0.66071429, 0.66071429, 0.64285714, 0.64285714,\n",
              "        0.64285714, 0.64285714, 0.64285714, 0.64285714, 0.64285714,\n",
              "        0.64285714, 0.64285714, 0.64285714, 0.64285714, 0.64285714,\n",
              "        0.64285714, 0.64285714, 0.64285714, 0.64285714, 0.64285714,\n",
              "        0.64285714, 0.64285714, 0.64285714, 0.64285714, 0.625     ,\n",
              "        0.60714286, 0.60714286, 0.60714286, 0.60714286, 0.60714286,\n",
              "        0.60714286, 0.60714286, 0.60714286, 0.60714286, 0.60714286,\n",
              "        0.60714286, 0.60714286, 0.60714286, 0.60714286, 0.58928571,\n",
              "        0.57142857, 0.57142857, 0.57142857, 0.57142857, 0.57142857,\n",
              "        0.57142857, 0.55357143, 0.55357143, 0.53571429, 0.53571429,\n",
              "        0.53571429, 0.53571429, 0.53571429, 0.53571429, 0.53571429,\n",
              "        0.53571429, 0.53571429, 0.53571429, 0.51785714, 0.51785714,\n",
              "        0.51785714, 0.51785714, 0.51785714, 0.51785714, 0.5       ,\n",
              "        0.5       , 0.5       , 0.48214286, 0.48214286, 0.46428571,\n",
              "        0.46428571, 0.46428571, 0.46428571, 0.46428571, 0.44642857,\n",
              "        0.42857143, 0.42857143, 0.42857143, 0.42857143, 0.42857143,\n",
              "        0.42857143, 0.42857143, 0.42857143, 0.42857143, 0.41071429,\n",
              "        0.39285714, 0.39285714, 0.39285714, 0.39285714, 0.39285714,\n",
              "        0.375     , 0.375     , 0.35714286, 0.33928571, 0.33928571,\n",
              "        0.32142857, 0.30357143, 0.28571429, 0.26785714, 0.26785714,\n",
              "        0.26785714, 0.26785714, 0.26785714, 0.25      , 0.23214286,\n",
              "        0.23214286, 0.23214286, 0.23214286, 0.23214286, 0.23214286,\n",
              "        0.21428571, 0.19642857, 0.17857143, 0.17857143, 0.17857143,\n",
              "        0.17857143, 0.17857143, 0.17857143, 0.17857143, 0.16071429,\n",
              "        0.14285714, 0.125     , 0.125     , 0.125     , 0.10714286,\n",
              "        0.08928571, 0.08928571, 0.08928571, 0.07142857, 0.07142857,\n",
              "        0.07142857, 0.05357143, 0.05357143, 0.05357143, 0.03571429,\n",
              "        0.01785714, 0.01785714, 0.01785714, 0.01785714, 0.01785714,\n",
              "        0.        ]),\n",
              " array([0.01377594, 0.01390283, 0.01393304, 0.01393622, 0.01412906,\n",
              "        0.01537562, 0.0155963 , 0.01651793, 0.01719101, 0.01769826,\n",
              "        0.01788545, 0.01836585, 0.01845112, 0.01864046, 0.01932366,\n",
              "        0.01949183, 0.02001805, 0.02005742, 0.02008501, 0.0204089 ,\n",
              "        0.02050066, 0.0210961 , 0.02113834, 0.02114997, 0.02133193,\n",
              "        0.02143958, 0.02151434, 0.0221708 , 0.02225047, 0.02270473,\n",
              "        0.02275254, 0.02295297, 0.02330096, 0.02354707, 0.02422054,\n",
              "        0.02426078, 0.02430234, 0.02531951, 0.02557309, 0.02562654,\n",
              "        0.02599097, 0.02621893, 0.02629094, 0.02642398, 0.02681495,\n",
              "        0.02694541, 0.02702173, 0.02754755, 0.02758617, 0.02772971,\n",
              "        0.0280243 , 0.02819053, 0.02819387, 0.02839627, 0.02853616,\n",
              "        0.02878458, 0.02886973, 0.03000233, 0.03018273, 0.03019719,\n",
              "        0.03029674, 0.03050639, 0.03060767, 0.03080461, 0.03095083,\n",
              "        0.03107834, 0.03136715, 0.03165205, 0.03182974, 0.03184134,\n",
              "        0.03187978, 0.03203258, 0.03208767, 0.03214691, 0.03217517,\n",
              "        0.03239262, 0.03241772, 0.0324743 , 0.03264579, 0.03310466,\n",
              "        0.03344406, 0.03358229, 0.03375932, 0.03395277, 0.03426744,\n",
              "        0.03430527, 0.03442599, 0.03447044, 0.03450207, 0.03469104,\n",
              "        0.03516607, 0.03535505, 0.03551682, 0.03552472, 0.03559475,\n",
              "        0.03572936, 0.03582572, 0.0359881 , 0.03617196, 0.0362109 ,\n",
              "        0.03629556, 0.03638739, 0.0365944 , 0.03674394, 0.03701372,\n",
              "        0.03717284, 0.0372485 , 0.03759032, 0.03767933, 0.03773787,\n",
              "        0.03811351, 0.0382596 , 0.03840169, 0.03875501, 0.03877578,\n",
              "        0.03911634, 0.03926506, 0.03934446, 0.03939043, 0.04016839,\n",
              "        0.04016982, 0.04022213, 0.04029011, 0.04042536, 0.04071053,\n",
              "        0.04078018, 0.04082242, 0.04088606, 0.04090154, 0.04110856,\n",
              "        0.0411657 , 0.0416692 , 0.04185805, 0.04197893, 0.04211513,\n",
              "        0.04244294, 0.04258785, 0.04269362, 0.04276225, 0.04280778,\n",
              "        0.04294117, 0.04307166, 0.04317965, 0.04322286, 0.04351714,\n",
              "        0.04370669, 0.04379677, 0.04387195, 0.04394464, 0.04420996,\n",
              "        0.04422216, 0.04440691, 0.04449736, 0.04453916, 0.04457095,\n",
              "        0.04462663, 0.04472641, 0.0448486 , 0.04507928, 0.045117  ,\n",
              "        0.0452296 , 0.04531971, 0.0454668 , 0.04569433, 0.04576558,\n",
              "        0.04585842, 0.04601419, 0.04640274, 0.04672748, 0.04676192,\n",
              "        0.04695645, 0.04696194, 0.04712733, 0.04718027, 0.04736813,\n",
              "        0.04745425, 0.04747437, 0.04757682, 0.04760882, 0.04773288,\n",
              "        0.04777183, 0.04781736, 0.04798776, 0.04820383, 0.04877904,\n",
              "        0.04879075, 0.04900133, 0.04931799, 0.04997103, 0.05029251,\n",
              "        0.05050904, 0.05083647, 0.05103897, 0.05105629, 0.05120637,\n",
              "        0.05127969, 0.05131288, 0.05188802, 0.05197534, 0.05200878,\n",
              "        0.05219839, 0.05229829, 0.05234727, 0.05245189, 0.05271738,\n",
              "        0.0528437 , 0.05304512, 0.05357317, 0.05414631, 0.05457659,\n",
              "        0.0546257 , 0.05492713, 0.05510074, 0.05532135, 0.0554767 ,\n",
              "        0.05564198, 0.05585305, 0.05600286, 0.05614965, 0.05615739,\n",
              "        0.05620952, 0.05620993, 0.05627579, 0.0563782 , 0.05643061,\n",
              "        0.056608  , 0.05723548, 0.05793721, 0.0579387 , 0.05797165,\n",
              "        0.05806931, 0.0582354 , 0.05827347, 0.0583282 , 0.05836274,\n",
              "        0.05867544, 0.05874892, 0.05892451, 0.05906032, 0.05912938,\n",
              "        0.05921785, 0.05959786, 0.0597057 , 0.05970882, 0.05977068,\n",
              "        0.05983304, 0.06013879, 0.06053378, 0.06063891, 0.06097586,\n",
              "        0.06112271, 0.06114579, 0.06115142, 0.06126591, 0.06147833,\n",
              "        0.0616656 , 0.06202732, 0.06213029, 0.06260309, 0.06265796,\n",
              "        0.06337523, 0.06351624, 0.06358697, 0.06360798, 0.063713  ,\n",
              "        0.06382811, 0.06383741, 0.063892  , 0.06391043, 0.06394954,\n",
              "        0.06404232, 0.06416333, 0.064348  , 0.06463542, 0.06524902,\n",
              "        0.065837  , 0.06592871, 0.06597411, 0.06618377, 0.06663202,\n",
              "        0.06665274, 0.06685098, 0.06688023, 0.06714501, 0.06761194,\n",
              "        0.06767955, 0.06769454, 0.06772646, 0.06791626, 0.0685795 ,\n",
              "        0.06893629, 0.06894347, 0.06921845, 0.06979518, 0.06983826,\n",
              "        0.07006434, 0.07008466, 0.07034763, 0.07046656, 0.07054917,\n",
              "        0.0707467 , 0.07077643, 0.07089235, 0.07090164, 0.07115137,\n",
              "        0.0711641 , 0.07187637, 0.07193907, 0.07200652, 0.07245109,\n",
              "        0.07311318, 0.07311718, 0.07341869, 0.07359474, 0.07360195,\n",
              "        0.0737692 , 0.07383746, 0.07388943, 0.07401191, 0.07403875,\n",
              "        0.07409825, 0.07444638, 0.07471979, 0.07490078, 0.07517473,\n",
              "        0.07536954, 0.07540002, 0.07543038, 0.07563525, 0.07572013,\n",
              "        0.075789  , 0.07599159, 0.07644264, 0.07656846, 0.07658547,\n",
              "        0.07660236, 0.07733046, 0.0775538 , 0.0776163 , 0.07787671,\n",
              "        0.07790603, 0.07793278, 0.07808741, 0.07848833, 0.07855169,\n",
              "        0.07877593, 0.07886051, 0.07892448, 0.0789827 , 0.07899163,\n",
              "        0.07935938, 0.08011709, 0.08062396, 0.08084828, 0.08094212,\n",
              "        0.0810464 , 0.08110106, 0.08117908, 0.081494  , 0.08162341,\n",
              "        0.08163802, 0.08215627, 0.08223268, 0.08224742, 0.08228471,\n",
              "        0.08300821, 0.0830707 , 0.08313928, 0.08322368, 0.08341672,\n",
              "        0.08347184, 0.08348151, 0.08372448, 0.0839935 , 0.08400767,\n",
              "        0.08464447, 0.08478718, 0.08480138, 0.08498695, 0.08500576,\n",
              "        0.08523487, 0.0853016 , 0.08543686, 0.08550937, 0.08562147,\n",
              "        0.0861423 , 0.08628862, 0.08634464, 0.08650348, 0.08715284,\n",
              "        0.08728788, 0.08739004, 0.08747372, 0.08787389, 0.08846749,\n",
              "        0.08853949, 0.08879249, 0.088987  , 0.08924227, 0.08930062,\n",
              "        0.08937217, 0.08953366, 0.08968296, 0.08985755, 0.08999246,\n",
              "        0.09081299, 0.09106393, 0.09112543, 0.09186212, 0.09203766,\n",
              "        0.09271079, 0.09298167, 0.09339403, 0.09362391, 0.09475818,\n",
              "        0.09569234, 0.09584546, 0.09598576, 0.09642216, 0.09659892,\n",
              "        0.09662921, 0.09667704, 0.09730825, 0.09809371, 0.09823424,\n",
              "        0.09834967, 0.09841435, 0.09856486, 0.09857398, 0.09898788,\n",
              "        0.0990293 , 0.09957054, 0.09973045, 0.10102113, 0.10113696,\n",
              "        0.1014736 , 0.10160168, 0.10177036, 0.10179856, 0.10193019,\n",
              "        0.10200857, 0.10294661, 0.10315688, 0.10380176, 0.10404587,\n",
              "        0.10423595, 0.10434193, 0.10488201, 0.10513078, 0.10576764,\n",
              "        0.10635644, 0.10691297, 0.10698003, 0.10699105, 0.10708881,\n",
              "        0.1077417 , 0.10827743, 0.10835359, 0.10849342, 0.10939004,\n",
              "        0.10949401, 0.10959466, 0.10982383, 0.10993253, 0.1100948 ,\n",
              "        0.11073876, 0.11082967, 0.11152698, 0.11181743, 0.11212415,\n",
              "        0.11277238, 0.1129441 , 0.1132772 , 0.1146648 , 0.11584605,\n",
              "        0.11592307, 0.11650799, 0.11741463, 0.11816531, 0.11831315,\n",
              "        0.11832148, 0.11880179, 0.11967624, 0.1198082 , 0.11984458,\n",
              "        0.12072128, 0.12171109, 0.122416  , 0.1226919 , 0.1230163 ,\n",
              "        0.12321316, 0.12367939, 0.12386962, 0.12392464, 0.12448461,\n",
              "        0.12544008, 0.12606987, 0.12622127, 0.12782897, 0.1301468 ,\n",
              "        0.13025913, 0.1324699 , 0.13275066, 0.13302551, 0.13312253,\n",
              "        0.13363959, 0.13483277, 0.13678893, 0.1373939 , 0.13833931,\n",
              "        0.13909557, 0.13995807, 0.14247413, 0.1427234 , 0.14295486,\n",
              "        0.14522856, 0.1461816 , 0.14637884, 0.14763129, 0.14891542,\n",
              "        0.14993389, 0.15004589, 0.15024677, 0.15210825, 0.1526622 ,\n",
              "        0.15296476, 0.1568367 , 0.15721536, 0.15834461, 0.15884395,\n",
              "        0.15888967, 0.1591    , 0.16144383, 0.16225863, 0.16259538,\n",
              "        0.16513793, 0.16567768, 0.1658377 , 0.1660563 , 0.16915922,\n",
              "        0.17202888, 0.17401154, 0.17458953, 0.17626375, 0.17673025,\n",
              "        0.17728351, 0.17791274, 0.18163751, 0.18240064, 0.18307826,\n",
              "        0.18358712, 0.18469049, 0.18510747, 0.18526411, 0.18580699,\n",
              "        0.18799342, 0.18843059, 0.18844838, 0.18958351, 0.19026218,\n",
              "        0.19027963, 0.19271676, 0.19305776, 0.19539505, 0.2033372 ,\n",
              "        0.20464942, 0.21061069, 0.21221246, 0.21515676, 0.21690632,\n",
              "        0.21694815, 0.2192895 , 0.21998456, 0.22258766, 0.22291617,\n",
              "        0.22389036, 0.22659807, 0.23033364, 0.23408946, 0.23452155,\n",
              "        0.23474766, 0.23548956, 0.2409627 , 0.24249731, 0.2437789 ,\n",
              "        0.2526879 , 0.25768408, 0.26100993, 0.26536134, 0.26719633,\n",
              "        0.26928148, 0.27179307, 0.27275753, 0.2760366 , 0.28599626,\n",
              "        0.28612086, 0.2871195 , 0.28809744, 0.2972453 , 0.30244848,\n",
              "        0.30564386, 0.30787763, 0.31021458, 0.3322971 , 0.33261132,\n",
              "        0.33473843, 0.33515134, 0.3469981 , 0.34720844, 0.34764457,\n",
              "        0.34855488, 0.35093683, 0.35280275, 0.35471383, 0.35478473,\n",
              "        0.3558569 , 0.36187968, 0.36859486, 0.36916867, 0.37212676,\n",
              "        0.38113654, 0.38448307, 0.38575512, 0.3928887 , 0.400353  ,\n",
              "        0.40307862, 0.40704313, 0.42022222, 0.4216172 , 0.43704212,\n",
              "        0.4378993 , 0.43904656, 0.4415221 , 0.44153413, 0.45462307,\n",
              "        0.46464983, 0.4782201 , 0.4787804 , 0.51339155, 0.52278626,\n",
              "        0.52809876, 0.5465104 , 0.5473067 , 0.5545046 , 0.5633604 ,\n",
              "        0.6165657 , 0.6187802 , 0.62123245, 0.6217848 , 0.64352375,\n",
              "        0.656536  , 0.6575479 , 0.6740666 , 0.68507725, 0.712016  ,\n",
              "        0.71748275, 0.72850436, 0.7366782 , 0.74078697, 0.8044856 ,\n",
              "        0.8184609 , 0.8374132 , 0.8377097 , 0.8406863 , 0.8493192 ,\n",
              "        0.9145051 , 0.94237196, 0.9426518 , 0.9566842 , 0.99437356],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}